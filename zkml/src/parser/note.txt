
running 1 test
GGUF version: v3
GGUF metadata: {"general.architecture": String("gpt2"), "general.file_type": Number(7), "general.name": String("gpt2"), "general.quantization_version": Number(2), "gpt2.attention.head_count": Number(12), "gpt2.attention.layer_norm_epsilon": Number(0.00001), "gpt2.block_count": Number(12), "gpt2.context_length": Number(1024), "gpt2.embedding_length": Number(768), "gpt2.feed_forward_length": Number(3072), "tokenizer.ggml.bos_token_id": Number(50256), "tokenizer.ggml.eos_token_id": Number(50256), "tokenizer.ggml.merges": Array [String("Ġ t"), String("Ġ a"), String("h e")], "tokenizer.ggml.model": String("gpt2"), "tokenizer.ggml.pre": String("gpt-2"), "tokenizer.ggml.token_type": Array [Number(1), Number(1), Number(1)], "tokenizer.ggml.tokens": Array [String("!"), String("\""), String("#")]}
GGUF metadata: ["gpt2.attention.layer_norm_epsilon", "tokenizer.ggml.model", "tokenizer.ggml.eos_token_id", "tokenizer.ggml.bos_token_id", "tokenizer.ggml.pre", "gpt2.context_length", "general.quantization_version", "gpt2.attention.head_count", "gpt2.block_count", "tokenizer.ggml.merges", "gpt2.embedding_length", "general.name", "gpt2.feed_forward_length", "general.architecture", "tokenizer.ggml.token_type", "general.file_type", "tokenizer.ggml.tokens"]
GGUF tensors: {"blk.7.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 70569984 }, "blk.5.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 55443456 }, "blk.0.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 2525184 }, "blk.5.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 57971712 }, "blk.11.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 22689792 }, "blk.3.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 40332288 }, "blk.11.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 25205760 }, "blk.0.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 1889280 }, "blk.1.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 10091520 }, "blk.8.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 78133248 }, "blk.1.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 10079232 }, "blk.4.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 50411520 }, "blk.4.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 47892480 }, "blk.6.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 63009792 }, "blk.5.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 52930560 }, "blk.7.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 68041728 }, "blk.0.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 9216 }, "blk.2.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 35291136 }, "blk.9.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 88215552 }, "blk.2.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 35294208 }, "blk.6.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 63003648 }, "blk.9.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 88212480 }, "blk.2.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 32765952 }, "token_embd.weight": TensorInfo { ggml_dtype: Q8_0, shape: [50257, 768], offset: 92301312 }, "blk.3.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 40329216 }, "blk.7.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 70560768 }, "blk.9.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 85054464 }, "blk.4.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 47889408 }, "blk.6.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 60490752 }, "blk.7.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 70573056 }, "blk.1.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 12610560 }, "blk.9.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 85687296 }, "blk.8.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 77491200 }, "blk.4.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 47253504 }, "blk.6.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 63006720 }, "blk.2.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 32130048 }, "blk.11.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 25199616 }, "blk.11.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 25211904 }, "blk.0.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 2519040 }, "blk.4.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 47880192 }, "blk.5.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 55449600 }, "blk.8.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 77494272 }, "blk.7.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 69931008 }, "blk.3.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 40326144 }, "blk.6.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 62370816 }, "blk.5.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 55452672 }, "blk.7.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 70563840 }, "blk.3.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 42854400 }, "blk.2.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 32133120 }, "blk.10.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 17648640 }, "blk.8.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 80655360 }, "blk.0.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 2528256 }, "blk.5.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 54810624 }, "blk.3.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 40320000 }, "blk.8.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 78127104 }, "blk.4.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 47904768 }, "blk.1.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 7560192 }, "blk.3.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 40323072 }, "blk.10.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 15129600 }, "blk.6.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 62373888 }, "blk.8.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 75611136 }, "output_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 90722304 }, "blk.2.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 32759808 }, "blk.1.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 7569408 }, "blk.1.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 10085376 }, "blk.0.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 5053440 }, "blk.1.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 12613632 }, "blk.2.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 32762880 }, "blk.4.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 45370368 }, "blk.0.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 1892352 }, "blk.0.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 2522112 }, "blk.5.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 54813696 }, "blk.8.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 78130176 }, "output_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 90725376 }, "blk.7.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 69934080 }, "blk.2.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 32784384 }, "blk.8.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 78145536 }, "blk.11.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 27734016 }, "blk.3.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 39690240 }, "blk.6.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 60481536 }, "blk.3.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 42851328 }, "blk.9.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 83162112 }, "blk.9.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 85681152 }, "blk.9.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 85690368 }, "blk.9.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 83171328 }, "blk.8.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 80652288 }, "blk.11.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 25202688 }, "blk.4.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 50414592 }, "blk.10.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 17009664 }, "blk.0.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 0 }, "blk.3.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 39693312 }, "blk.6.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 63025152 }, "blk.6.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 65534976 }, "blk.7.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 73095168 }, "position_embd.weight": TensorInfo { ggml_dtype: F16, shape: [1024, 768], offset: 90728448 }, "output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [50257, 768], offset: 133311040 }, "blk.7.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 68050944 }, "blk.11.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 24572928 }, "blk.11.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 25208832 }, "blk.4.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 47250432 }, "blk.10.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 17645568 }, "blk.0.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 2531328 }, "blk.11.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 27730944 }, "blk.6.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 65531904 }, "blk.7.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 73092096 }, "blk.9.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 85693440 }, "blk.2.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 32772096 }, "blk.10.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 17639424 }, "blk.10.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 20173824 }, "blk.7.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 70566912 }, "blk.8.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 75601920 }, "blk.1.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 10082304 }, "blk.9.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 85051392 }, "blk.9.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 85684224 }, "blk.11.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 25224192 }, "blk.6.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 63012864 }, "blk.10.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 17642496 }, "blk.4.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 47883264 }, "blk.6.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 63000576 }, "blk.1.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 10088448 }, "blk.4.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 47886336 }, "blk.10.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 17664000 }, "blk.7.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 70585344 }, "blk.1.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 9449472 }, "blk.5.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 55440384 }, "blk.11.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 22680576 }, "blk.0.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 5050368 }, "blk.2.ffn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 32769024 }, "blk.1.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 10103808 }, "blk.8.attn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 78120960 }, "blk.8.attn_norm.weight": TensorInfo { ggml_dtype: F32, shape: [768], offset: 78124032 }, "blk.1.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 9452544 }, "blk.5.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 52921344 }, "blk.5.ffn_norm.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 55446528 }, "blk.2.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 30240768 }, "blk.3.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 40344576 }, "blk.9.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 85705728 }, "blk.10.attn_output.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 768], offset: 17012736 }, "blk.11.attn_output.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 24569856 }, "blk.4.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 45361152 }, "blk.5.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 55464960 }, "blk.10.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 15120384 }, "blk.2.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 30249984 }, "blk.3.attn_qkv.bias": TensorInfo { ggml_dtype: F32, shape: [2304], offset: 37800960 }, "blk.5.ffn_down.weight": TensorInfo { ggml_dtype: Q8_0, shape: [768, 3072], offset: 57974784 }, "blk.10.ffn_down.bias": TensorInfo { ggml_dtype: F32, shape: [768], offset: 20170752 }, "blk.10.ffn_up.bias": TensorInfo { ggml_dtype: F32, shape: [3072], offset: 17651712 }, "blk.3.attn_qkv.weight": TensorInfo { ggml_dtype: Q8_0, shape: [2304, 768], offset: 37810176 }, "blk.0.ffn_up.weight": TensorInfo { ggml_dtype: Q8_0, shape: [3072, 768], offset: 2543616 }}
Tensor name: blk.0.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.0.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.0.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.0.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.0.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.0.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.0.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.0.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.0.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.0.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.0.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.0.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.1.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.1.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.1.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.1.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.1.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.1.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.1.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.1.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.1.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.1.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.1.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.1.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.10.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.10.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.10.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.10.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.10.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.10.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.10.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.10.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.10.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.10.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.10.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.10.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.11.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.11.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.11.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.11.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.11.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.11.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.11.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.11.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.11.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.11.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.11.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.11.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.2.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.2.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.2.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.2.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.2.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.2.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.2.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.2.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.2.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.2.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.2.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.2.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.3.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.3.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.3.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.3.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.3.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.3.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.3.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.3.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.3.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.3.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.3.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.3.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.4.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.4.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.4.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.4.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.4.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.4.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.4.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.4.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.4.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.4.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.4.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.4.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.5.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.5.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.5.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.5.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.5.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.5.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.5.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.5.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.5.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.5.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.5.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.5.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.6.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.6.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.6.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.6.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.6.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.6.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.6.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.6.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.6.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.6.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.6.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.6.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.7.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.7.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.7.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.7.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.7.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.7.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.7.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.7.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.7.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.7.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.7.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.7.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.8.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.8.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.8.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.8.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.8.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.8.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.8.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.8.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.8.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.8.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.8.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.8.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: blk.9.attn_qkv.bias
Tensor kind: 0
Tensor shape: [2304, 1, 1, 1] -> total 2304
Tensor name: blk.9.attn_qkv.weight
Tensor kind: 8
Tensor shape: [768, 2304, 1, 1] -> total 1769472
Tensor name: blk.9.attn_output.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.9.attn_output.weight
Tensor kind: 8
Tensor shape: [768, 768, 1, 1] -> total 589824
Tensor name: blk.9.attn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.9.attn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.9.ffn_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.9.ffn_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.9.ffn_up.bias
Tensor kind: 0
Tensor shape: [3072, 1, 1, 1] -> total 3072
Tensor name: blk.9.ffn_up.weight
Tensor kind: 8
Tensor shape: [768, 3072, 1, 1] -> total 2359296
Tensor name: blk.9.ffn_down.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: blk.9.ffn_down.weight
Tensor kind: 8
Tensor shape: [3072, 768, 1, 1] -> total 2359296
Tensor name: output_norm.bias
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: output_norm.weight
Tensor kind: 0
Tensor shape: [768, 1, 1, 1] -> total 768
Tensor name: position_embd.weight
Tensor kind: 1
Tensor shape: [768, 1024, 1, 1] -> total 786432
Tensor name: token_embd.weight
Tensor kind: 8
Tensor shape: [768, 50257, 1, 1] -> total 38597376
Tensor name: output.weight
Tensor kind: 8
Tensor shape: [768, 50257, 1, 1] -> total 38597376
test parser::gguf::tests::test_load_and_inspect_gpt2_gguf ... ok