use std::{any, cmp::max};

use anyhow::{bail, ensure, Context as CContext};
use ff_ext::ExtensionField;
use itertools::Itertools;
use log::debug;
use multilinear_extensions::{
    mle::{IntoMLE, IntoMLEs, MultilinearExtension},
    virtual_poly::{VPAuxInfo, VirtualPolynomial},
};
use serde::{Deserialize, Serialize, de::DeserializeOwned};
use sumcheck::structs::{IOPProof, IOPProverState, IOPVerifierState};
use transcript::{BasicTranscript, Transcript};

use crate::{
    activation::{Activation, ActivationCtx}, claims::{precommit::{self, PolyID}, same_poly}, lookup::{self, LookupProtocol}, matrix::Matrix, model::{InferenceStep, InferenceTrace, Layer, Model, StepIdx}, vector_to_mle, Claim, Element, VectorTranscript
};

/// Contains all cryptographic material generated by the prover
#[derive(Clone, Serialize, Deserialize)]
#[serde(bound(serialize = "E: Serialize", deserialize = "E: DeserializeOwned"))]
pub struct Proof<E: ExtensionField>
where
    E::BaseField: Serialize + DeserializeOwned,
    E: Serialize + DeserializeOwned,
{
    /// The successive sumchecks proofs. From output layer to input.
    steps: Vec<StepProof<E>>,
    commit: precommit::CommitProof<E>,
}

/// Contains proof material related to one step of the inference
#[derive(Default, Clone, Serialize, Deserialize)]
pub struct StepProof<E: ExtensionField> {
    /// the actual sumcheck proof
    proof: IOPProof<E>,
    /// The individual evaluations of the individual polynomial for the last random part of the
    /// sumcheck. One for each polynomial involved in the "virtual poly". Since we only support quadratic right now it's
    /// a flat list.
    individual_claims: Vec<E>,
}

impl<E: ExtensionField> StepProof<E> {
    /// Returns the individual claims f_1(r) f_2(r)  f_3(r) ... at the end of a sumcheck multiplied
    /// together
    pub fn individual_to_virtual_claim(&self) -> E {
        self.individual_claims.iter().fold(E::ONE, |acc, e| acc * e)
    }
}

/// What the verifier must have besides the proof
pub struct IO<E> {
    /// Input of the inference given to the model
    input: Vec<E>,
    /// Output of the inference
    output: Vec<E>,
}

impl<E> IO<E> {
    pub fn new(input: Vec<E>, output: Vec<E>) -> Self {
        Self { input, output }
    }
}

/// Common information between prover and verifier
#[derive(Clone, Debug, Serialize, Deserialize)]
#[serde(bound(serialize = "E: Serialize", deserialize = "E: DeserializeOwned"))]
pub struct Context<E: ExtensionField>
where
    E::BaseField: Serialize + DeserializeOwned,
    E: Serialize + DeserializeOwned,
{
    /// Dimensions of the polynomials necessary to verify the sumcheck proofs
    /// These poly are from the matrices weights
    /// in REVERSED order already since proving goes from last layer to first layer.
    polys_aux: Vec<(PolyID, VPAuxInfo<E>)>,
    /// Context related to the commitment and accumulation of claims related to the weights of model.
    /// This part contains the commitment of the weights.
    weights: precommit::Context<E>,

    /// Context holding the lookup tables for activation, e.g. the MLEs of the input and output columns for 
    /// RELU for example
    activation: ActivationCtx<E>,
    
}

impl<E: ExtensionField> Context<E>
where
    E::BaseField: Serialize + DeserializeOwned,
    E: Serialize + DeserializeOwned,
{
    /// Generates a context to give to the verifier that contains informations about the polynomials
    /// to prove at each step.
    /// INFO: it _assumes_ the model is already well padded to power of twos.
    pub fn generate(model: &Model) -> anyhow::Result<Self> {
        let auxs = model
            .layers()
            .map(|(id, layer)| {
                match layer {
                    Layer::Dense(matrix) => {
                        // construct dimension of the polynomial given to the sumcheck
                        let ncols = matrix.ncols();
                        // each poly is only two polynomial right now: matrix and vector
                        // for matrix, each time we fix the variables related to rows so we are only left
                        // with the variables related to columns
                        let matrix_num_vars = ncols.ilog2() as usize;
                        let vector_num_vars = matrix_num_vars;
                        // there is only one product (i.e. quadratic sumcheck)
                        (
                            id,
                            VPAuxInfo::<E>::from_mle_list_dimensions(&vec![vec![
                                matrix_num_vars,
                                vector_num_vars,
                            ]]),
                        )
                    } 
                    _ => unimplemented!(),
                }
            })
            .rev()
            .collect_vec();
        let commit_ctx = precommit::Context::generate_from_model(model)
            .context("can't generate context for commitment part")?;
        let activation = ActivationCtx::new();
        Ok(Self {
            polys_aux: auxs,
            weights: commit_ctx,
            activation,
        })
    }

    pub fn write_to_transcript<T: Transcript<E>>(&self, t: &mut T) -> anyhow::Result<()> {
        for (id, poly_info) in self.polys_aux.iter() {
            t.append_field_element(&E::BaseField::from(*id as u64));
            poly_info.write_to_transcript(t);
        }
        self.weights.write_to_transcript(t)?;
        Ok(())
    }
}

/// Prover generates a series of sumcheck proofs to prove the inference of a model
pub struct Prover<'a, E: ExtensionField, T: Transcript<E>> 
where
    E::BaseField: Serialize + DeserializeOwned,
    E: Serialize + DeserializeOwned
{
    ctx: &'a Context<E>,
    // proofs for each layer being filled
    proofs: Vec<StepProof<E>>,
    transcript: &'a mut T,
    commit_prover: precommit::CommitProver<E>,
    /// the context of the witness part (IO of lookups, linked with matrix2vec for example)
    /// is generated during proving time. It is first generated and then the fiat shamir starts.
    /// The verifier doesn't know about the individual polys (otherwise it beats the purpose) so 
    /// that's why it is generated at proof time.
    witness_ctx: Option<precommit::Context<E>>,
    /// The prover related to proving multiple claims about different witness polyy (io of lookups etc)
    witness_prover: precommit::CommitProver<E>,
}

/// Returns the default transcript the prover and verifier must instantiate to validate a proof.
pub fn default_transcript<E: ExtensionField>() -> BasicTranscript<E> {
    BasicTranscript::new(b"m2vec")
}

impl<'a, E, T> Prover<'a, E, T>
where
    T: Transcript<E>,
    E: ExtensionField,
    E::BaseField: Serialize + DeserializeOwned,
    E: Serialize + DeserializeOwned,
{
    pub fn new(ctx: &'a Context<E>,transcript: &'a mut T) -> Self {
        Self {
            ctx,
            transcript,
            proofs: Default::default(),
            commit_prover: precommit::CommitProver::new(),
            // at this step, we can't build the ctx since we don't know the individual polys
            witness_ctx: None,
            witness_prover: precommit::CommitProver::new(),
        }
    }
    fn prove_step<'b>(
        &mut self,
        last_claim: Claim<E>,
        input: &[E],
        step: &InferenceStep<'b, E>,
    ) -> anyhow::Result<Claim<E>> {
        match step.layer {
            Layer::Dense(matrix) => {
                // NOTE: here we treat the ID of the step AS the ID of the polynomial. THat's okay because we only care
                // about these IDs being unique, so as long as the mapping between poly <-> id is correct, all good.
                // This is the case here since we treat each matrix as a different poly
                self.prove_dense_step(last_claim, input, &step.output, (step.id as PolyID, matrix))
            }
            Layer::Activation(crate::activation::Activation::Relu(relu)) => self.prove_relu(last_claim, input, &step.output, step.id)
        }
    }

    fn prove_relu(&mut self,
        last_claim: Claim<E>,
        // input to the relu
        input: &[E],
        // output of the relu
        output: &[E],
        // the step_id is used to associate the polys to accumulate for this lookup argument
        step_id: StepIdx) -> anyhow::Result<Claim<E>> {
            // First call the lookup with the right arguments:
            // * table mle: one mle per column
            // * lookup mle: one mle per column, where the evals are just the list of inputs and output ordered by access
            let table_mles = self.ctx.activation.relu_polys().into_mles();
            let lookup_mles = vec![input.to_vec(),output.to_vec()].into_mles();
            // TODO: replace via proper lookup protocol
            let mut lookup_proof = lookup::DummyLookup::prove(table_mles,lookup_mles,self.transcript)?;
             // in our case, the output of the RELU is ALSO the same poly that previous proving
            // step (likely dense) has "outputted" to evaluate at a random point. So here we accumulate the two claims,
            // the one from previous proving step and the one given by the lookup protocol into one. Since they're claims
            // about the same poly, we can use the "same_poly" protocol.
            let same_poly_ctx = same_poly::Context::<E>::new(output.len()) ;
            let mut same_poly_prover = same_poly::Prover::<E>::new(output.to_vec().into_mle());
            same_poly_prover.add_claim(last_claim)?;
            let (input_claim,output_claim) = (lookup_proof.claims.remove(0),lookup_proof.claims.remove(0));
            same_poly_prover.add_claim(output_claim)?;
            let claim_acc_proof = same_poly_prover.prove(&same_poly_ctx, self.transcript)?;
            // order is (input,output,mult)
            // TODO: add multiplicities
            self.witness_prover.add_claim(step_id*3, input_claim)?;
            self.witness_prover.add_claim(step_id * 3, claim_acc_proof.extract_claim())?;
            // now this accumulated claim, we insert it as the 
            //let mut accumulator = same_poly::Prover::new();
            //accumulator.add_claim(last_claim.point, last_claim.eval);
        
        // the next step is gonna take care of proving the next claim
        // TODO: this is wrong
        Ok(claim_acc_proof.extract_claim())
    }

    fn prove_dense_step(
        &mut self,
        // last random claim made
        last_claim: Claim<E>,
        // input to the dense layer
        input: &[E],
        // output of dense layer evaluation
        output: &[E],
        (id, matrix): (PolyID, &Matrix<Element>),
    ) -> anyhow::Result<Claim<E>> {
        let (nrows, ncols) = (matrix.nrows(), matrix.ncols());
        assert_eq!(nrows, output.len(), "something's wrong with the output");
        assert_eq!(
            nrows.ilog2() as usize,
            last_claim.point.len(),
            "something's wrong with the randomness"
        );
        assert_eq!(ncols, input.len(), "something's wrong with the input");
        // contruct the MLE combining the input and the matrix
        let mut mat_mle = matrix.to_mle();
        // fix the variables from the random input
        // NOTE: here we must fix the HIGH variables because the MLE is addressing in little
        // endian so (rows,cols) is actually given in (cols, rows)
        // mat_mle.fix_variables_in_place_parallel(partial_point);
        mat_mle.fix_high_variables_in_place(&last_claim.point);
        let input_mle = vector_to_mle(input.to_vec());
        let max_var = max(mat_mle.num_vars(), input_mle.num_vars());
        assert_eq!(mat_mle.num_vars(), input_mle.num_vars());
        let mut vp = VirtualPolynomial::<E>::new(max_var);
        // TODO: remove the clone once prover+verifier are working
        vp.add_mle_list(
            vec![mat_mle.clone().into(), input_mle.clone().into()],
            E::ONE,
        );
        let tmp_transcript = self.transcript.clone();
        #[allow(deprecated)]
        let (proof, state) = IOPProverState::<E>::prove_parallel(vp, self.transcript);

        debug_assert!({
            let mut t = tmp_transcript;
            // just construct manually here instead of cloning in the non debug code
            let mut vp = VirtualPolynomial::<E>::new(max_var);
            vp.add_mle_list(vec![mat_mle.into(), input_mle.into()], E::ONE);
            // asserted_sum in this case is the output MLE evaluated at the random point
            let mle_output = vector_to_mle(output.to_vec());
            let claimed_sum = mle_output.evaluate(&last_claim.point);
            debug_assert_eq!(claimed_sum, proof.extract_sum(), "sumcheck output weird");
            debug_assert_eq!(claimed_sum, last_claim.eval);

            debug!("prover: claimed sum: {:?}", claimed_sum);
            let subclaim = IOPVerifierState::<E>::verify(claimed_sum, &proof, &vp.aux_info, &mut t);
            // now assert that the polynomial evaluated at the random point of the sumcheck proof
            // is equal to last small poly sent by prover (`subclaim.expected_evaluation`). This
            // step can be done via PCS opening proofs for all steps but first (output of
            // inference) and last (input of inference)
            let computed_point = vp.evaluate(subclaim.point_flat().as_ref());

            let final_prover_point = state
                .get_mle_final_evaluations()
                .into_iter()
                .fold(E::ONE, |acc, eval| acc * eval);
            assert_eq!(computed_point, final_prover_point);

            // NOTE: this expected_evaluation is computed by the verifier on the "reduced"
            // last polynomial of the sumcheck protocol. It's easy to compute since it's a degree
            // one poly. However, it needs to be checked against the original polynomial and this
            // is done via PCS.
            computed_point == subclaim.expected_evaluation
        });

        // PCS part: here we need to create an opening proof for the final evaluation of the matrix poly
        // Note we need the _full_ input to the matrix since the matrix MLE has (row,column) vars space
        let point = [proof.point.as_slice(), last_claim.point.as_slice()].concat();
        let eval = state.get_mle_final_evaluations()[0];
        self.commit_prover
            .add_claim(id, Claim::from(point, eval))
            .context("unable to add claim")?;

        // the claim that this proving step outputs is the claim about not the matrix but the vector poly. 
        // at next step, that claim will be proven over this vector poly (either by the next dense layer proving, or RELU etc).
        let claim = Claim {
            point: proof.point.clone(),
            eval: state.get_mle_final_evaluations()[1],
        };
        self.push_step_proof(proof, state.get_mle_final_evaluations());
        Ok(claim)
    }

    pub fn prove<'b>(
        mut self,
        trace: InferenceTrace<'b, E>,
    ) -> anyhow::Result<Proof<E>> {
        // First, create the context for the witness polys - 
        self.instantiate_witness_ctx(&trace)?;
        // write commitments and polynomials info to transcript
        self.ctx.write_to_transcript(self.transcript)?;
        // this is the random set of variables to fix at each step derived as the output of
        // sumcheck.
        // For the first step, so before the first sumcheck, we generate it from FS.
        // The dimension is simply the number of variables needed to address all the space of the
        // input vector.
        let r_i = self
            .transcript
            .read_challenges(trace.final_output().len().ilog2() as usize);
        let y_i = vector_to_mle(trace.last_step().output.clone()).evaluate(&r_i);
        let mut last_claim = Claim {
            point: r_i,
            eval: y_i,
        };
        // we start by the output to prove up to the input, GKR style
        for (i, (input, step)) in trace.iter().rev().enumerate() {
            last_claim = self.prove_step(last_claim, input, step)?;
        }
        // now provide opening proofs for all claims accumulated during the proving steps
        let commit_proof = self.commit_prover.prove(&self.ctx.weights, self.transcript)?;
        Ok(Proof {
            steps: self.proofs,
            commit: commit_proof,
        })
    }

    /// Appends a new step to the list of proofs
    pub fn push_step_proof(&mut self, proof: IOPProof<E>, individual_claims: Vec<E>) {
        self.proofs.push(StepProof {
            proof,
            individual_claims,
        });
    }
    /// Looks at all the individual polys to accumulate from the witnesses and create the context from that.
    fn instantiate_witness_ctx<'b>(&mut self, trace: &InferenceTrace<'b,E>) -> anyhow::Result<()> {
        let polys = trace.iter().rev().filter_map(|(input,step)| {
            match step.layer {
                Layer::Activation(Activation::Relu(_)) =>  {
                    // We need distinct poly id and at each step we "accumulate" 3 poly
                    // we can "expand" the set of IDs of polys we commit to here since they're proven fully separated
                    // from the matrices weight IDs.
                    let base_id = step.id * 3;
                    // TODO: right now we accumulate the input and output, also need to accumulate 
                    // the multiplicities poly
                    Some(vec![(base_id + 0, input.to_vec()),(base_id + 1, step.output.clone())])
                },
                // the dense layer is handling everything "on its own"
                Layer::Dense(_) => None,
            }
        }).flatten().collect_vec();
        let ctx = precommit::Context::generate(polys).context("unable to generate ctx for witnesses")?;
        self.witness_ctx = Some(ctx);
        Ok(())
    }
}

/// Verifies an inference proof given a context, a proof and the input / output of the model.
pub fn verify<E: ExtensionField, T: Transcript<E>>(
    ctx: Context<E>,
    proof: Proof<E>,
    io: IO<E>,
    transcript: &mut T,
) -> anyhow::Result<()>
where
    E::BaseField: Serialize + DeserializeOwned,
    E: Serialize + DeserializeOwned,
{
    let mut commit_verifier = precommit::CommitVerifier::new();
    ctx.write_to_transcript(transcript)?;
    // 0. Derive the first randomness
    let mut randomness_to_fix = transcript.read_challenges(io.output.len().ilog2() as usize);
    // 1. For the output, we manually evaluate the MLE and check if it's the same as what prover
    //    gave. Note prover could ellude that but it's simpler to avoid that special check right
    //    now.
    let output_mle = vector_to_mle(io.output);
    let computed_sum = output_mle.evaluate(&randomness_to_fix);
    let mut claimed_sum = proof
        .steps
        .first()
        .expect("at least one layer")
        .proof
        // checks that the last g(0) + g(1) is really equal to the output that the verifier's
        // expecting (random evaluation of the output)
        .extract_sum();

    ensure!(
        computed_sum == claimed_sum,
        "output vector evaluation is incorrect"
    );
    // let layers = ctx.model.layers().collect_vec();
    // let nlayers = layers.len();

    // 2. Verify each proof sequentially
    for (i, (step, (id, aux))) in proof.steps.iter().zip(ctx.polys_aux).enumerate() {
        debug!("verify {}: aux {:?}", i, aux);
        // TODO: currently that API can panic - should remove panic for error
        let subclaim = IOPVerifierState::<E>::verify(claimed_sum, &step.proof, &aux, transcript);

        // MATRIX OPENING PART
        // pcs_eval means this evaluation should come from a PCS opening proof
        let pcs_eval_input = subclaim
            .point_flat()
            .iter()
            .chain(randomness_to_fix.iter())
            .cloned()
            .collect_vec();
        // 0 because Matrix comes first in Matrix x Vector
        // Note we don't care about verifying that for the vector since it's verified at the next
        // step.
        let pcs_eval_output = step.individual_claims[0];
        commit_verifier.add_claim(id, Claim::from(pcs_eval_input, pcs_eval_output))?;

        // SUMCHECK verification part
        // Instead of computing the polynomial at the random point requested like this
        // let computed_point = vp.evaluate(
        //     subclaim
        //         .point
        //         .iter()
        //         .map(|c| c.elements)
        //         .collect_vec()
        //         .as_ref(),
        //
        // We compute the evaluation directly from the individual final evaluations of each polynomial
        // involved in the sumcheck the prover's giving,e.g. y(res) = SUM f_i(res)
        ensure!(
            step.individual_to_virtual_claim() == subclaim.expected_evaluation,
            "step {}: sumcheck claim failed",
            i
        );

        // the new randomness to fix at next layer is the randomness from the sumcheck !
        randomness_to_fix = subclaim.point_flat();
        // the claimed sum for the next sumcheck is MLE of the current vector evaluated at the
        // random point. 1 because vector is secondary.
        claimed_sum = step.individual_claims[1];
    }
    // 3. input verification: evaluating the input at the random evaluation point from the sumcheck
    let input_mle = vector_to_mle(io.input);
    let computed_randomized_input = input_mle.evaluate(&randomness_to_fix);
    let given_randomized_input = proof
        .steps
        .last()
        .expect("at least one layer")
        .individual_claims[1];
    ensure!(
        computed_randomized_input == given_randomized_input,
        "input not valid from proof"
    );
    // 4. verify the opening of the accumulation of claims
    commit_verifier.verify(&ctx.weights, proof.commit, transcript)?;
    Ok(())
}

#[cfg(test)]
mod test {
    use goldilocks::GoldilocksExt2;

    use crate::{model::Model, vector_to_field_par};

    use super::{Context, IO, Prover, default_transcript, verify};

    type F = GoldilocksExt2;
    use tracing_subscriber;

    #[test]
    fn test_prover_steps() {
        tracing_subscriber::fmt::init();
        let (model, input) = Model::random(4);
        let trace = model.run::<F>(input.clone());
        let output = trace.final_output();
        let ctx = Context::generate(&model).expect("unable to generate context");
        let io = IO::new(vector_to_field_par(&input), output.to_vec());
        let mut prover_transcript = default_transcript();
        let prover = Prover::new(&ctx, &mut prover_transcript);
        let proof = prover.prove(trace).expect("unable to generate proof");
        let mut verifier_transcript = default_transcript();
        verify(ctx, proof, io, &mut verifier_transcript).expect("invalid proof");
    }

    //#[test]
    // fn test_sumcheck_evals() {
    //    type F = GoldilocksExt2;
    //    let n = (10 as usize).next_power_of_two();
    //    let mat = Matrix::random((2 * n, n)).pad_next_power_of_two();
    //    let vec = random_vector(n);
    //    let sum = mat.matmul(&vec);
    //    let mle1 = mat.to_mle();
    //    let mle2 = vector_to_mle(vec);

    //    let vp = VirtualPolynomial::new(n.ilog2() as usize);
    //    vp.add_mle_list(vec![mle1.clone().into(), mle2.clone().into()], F::ONE);
    //    let poly_info = vp.aux_info.clone();
    //    #[allow(deprecated)]
    //    let (proof, _) = IOPProverState::<F>::prove_parallel(vp.clone(), &mut transcript);

    //    let mut transcript = BasicTranscript::new(b"test");
    //    let subclaim = IOPVerifierState::<F>::verify(sum, &proof, &poly_info, &mut transcript);
    //    assert!(
    //        vp.evaluate(
    //            subclaim
    //                .point
    //                .iter()
    //                .map(|c| c.elements)
    //                .collect::<Vec<_>>()
    //                .as_ref()
    //        ) == subclaim.expected_evaluation,
    //        "wrong subclaim"
    //    );
    //}
}
