use std::{cmp::max, iter::Step};

use anyhow::ensure;
use ark_std::rand::random;
use ff_ext::ExtensionField;
use itertools::Itertools;
use log::info;
use multilinear_extensions::{
    mle::MultilinearExtension,
    virtual_poly::{VPAuxInfo, VirtualPolynomial},
};
use serde::{Deserialize, Serialize};
use sumcheck::structs::{IOPProof, IOPProverState, IOPVerifierState};
use transcript::{BasicTranscript, Transcript};

use crate::{
    VectorTranscript,
    matrix::Matrix,
    model::{InferenceStep, InferenceTrace, Layer, Model},
    vector_to_mle,
};

/// Contains all cryptographic material generated by the prover
#[derive(Default, Clone, Serialize, Deserialize)]
struct Proof<E: ExtensionField> {
    /// The successive sumchecks proofs. From output layer to input.
    steps: Vec<StepProof<E>>,
}

#[derive(Default, Clone, Serialize, Deserialize)]
struct StepProof<E> {
    /// the actual sumcheck proof
    proof: IOPProof<E>,
    /// The claimed sum for which the sumcheck is being called upon.
    /// This is necessary to provide as the verifier doesn't have access to intermediary layers and
    /// thus can't compute this on its own.
    /// Example:
    ///  * y_1  = M1 x v
    ///  * y_2 =  M2 * y_1
    /// Verifier doesn't have y_1 since the model is not known so prover gives y_1(r) where r is
    /// the randomness that comes from either previous layer or FS at the beginning.
    claimed_output: E,
}

impl<E: ExtensionField> Proof<E> {
    pub fn push_step_proof(&mut self, proof: IOPProof<E>, claimed_output: E) {
        self.steps.push(StepProof {
            proof,
            claimed_output,
        });
    }
}

/// What the verifier must have besides the proof
struct IO<E> {
    input: Vec<E>,
    output: Vec<E>,
}

impl<E> IO<E> {
    pub fn new(input: Vec<E>, output: Vec<E>) -> Self {
        Self { input, output }
    }
}

/// Common information between prover and verifier
struct Context<E> {
    /// Dimensions of the polynomials necessary to verify the sumcheck proofs
    polys_aux: Vec<VPAuxInfo<E>>,
    /// TO DISAPPEAR: the model is there to give access to the verifier to the layers
    /// Normally the verifier only has access to the commitment(s)
    model: Model<E>,
}

impl<E: ExtensionField> Context<E> {
    // INFO: it _assumes_ the model is already well padded to power of twos.
    pub fn generate(model: &Model<E>) -> Self {
        let auxs = model
            .layers()
            .iter()
            .map(|layer| {
                // construct dimension of the polynomial given to the sumcheck
                let (nrows, ncols) = layer.dim();
                // each poly is only two polynomial right now: matrix and vector
                // for matrix, each time we fix the variables related to rows so we are only left
                // with the variables related to columns
                let matrix_num_vars = ncols.ilog2() as usize;
                let vector_num_vars = ncols.ilog2() as usize;
                // there is only one product (i.e. quadratic sumcheck)
                VPAuxInfo::<E>::from_mle_list_dimensions(&vec![vec![
                    matrix_num_vars,
                    vector_num_vars,
                ]])
            })
            .collect_vec();
        Self {
            polys_aux: auxs,
            model: model.clone(),
        }
    }

    /// Returns the number of layers there are in the model
    pub fn len(&self) -> usize {
        self.model.layers().len()
    }

    /// This replaces the PCS in the meantime
    pub fn evaluate_layer(&self, index: usize, input: &[E]) -> E {
        self.model
            .layers()
            .get(index)
            .expect("invalid layer addressing")
            .mle()
            .evaluate(input)
    }
}

struct Prover<E: ExtensionField> {
    transcript: BasicTranscript<E>,
    // proof being filled
    proof: Proof<E>,
}

pub fn default_transcript<E: ExtensionField>() -> BasicTranscript<E> {
    BasicTranscript::new(b"m2vec")
}

impl<E> Prover<E>
where
    E: ExtensionField,
{
    pub fn new() -> Self {
        Self {
            transcript: default_transcript(),
            proof: Default::default(),
        }
    }
    fn prove_step<'a>(
        &mut self,
        random_vars_to_fix: Vec<E>,
        input: &[E],
        step: &InferenceStep<'a, E>,
    ) {
        match step.layer {
            Layer::Dense(matrix) => {
                self.prove_dense_step(random_vars_to_fix, input, &step.output, matrix)
            }
        }
    }
    fn prove_dense_step(
        &mut self,
        random_vars_to_fix: Vec<E>,
        input: &[E],
        output: &[E],
        matrix: &Matrix<E>,
    ) {
        let (nrows, ncols) = (matrix.nrows(), matrix.ncols());
        assert_eq!(nrows, output.len(), "something's wrong with the output");
        assert_eq!(
            nrows.ilog2() as usize,
            random_vars_to_fix.len(),
            "something's wrong with the randomness"
        );
        assert_eq!(ncols, input.len(), "something's wrong with the input");
        // contruct the MLE combining the input and the matrix
        let mut mat_mle = matrix.to_mle();
        // fix the variables from the random input
        // NOTE: here we must fix the HIGH variables because the MLE is addressing in little
        // endian so (rows,cols) is actually given in (cols, rows)
        // mat_mle.fix_variables_in_place_parallel(partial_point);
        println!("mat_mle before fixing: {}", mat_mle.num_vars());
        mat_mle.fix_high_variables_in_place(&random_vars_to_fix);
        println!("mat_mle after fixing: {}", mat_mle.num_vars());
        let input_mle = vector_to_mle(input.to_vec());
        println!("INPUT num vars {}", input_mle.num_vars());
        let max_var = max(mat_mle.num_vars(), input_mle.num_vars());
        let mut vp = VirtualPolynomial::<E>::new(max_var);
        // TODO: remove the clone once prover+verifier are working
        vp.add_mle_list(
            vec![mat_mle.clone().into(), input_mle.clone().into()],
            E::ONE,
        );
        let tmp_transcript = self.transcript.clone();
        let (proof, _) = IOPProverState::<E>::prove_parallel(vp, &mut self.transcript);
        // asserted_sum in this case is the output MLE evaluated at the random point
        let mle_output = vector_to_mle(output.to_vec());
        let claimed_sum = mle_output.evaluate(&random_vars_to_fix);

        debug_assert!({
            let mut t = tmp_transcript;
            // just construct manually here instead of cloning in the non debug code
            let mut vp = VirtualPolynomial::<E>::new(max_var);
            vp.add_mle_list(vec![mat_mle.into(), input_mle.into()], E::ONE);
            println!("prove : aux {:?}", vp.aux_info);
            let subclaim = IOPVerifierState::<E>::verify(claimed_sum, &proof, &vp.aux_info, &mut t);
            // now assert that the polynomial evaluated at the random point of the sumcheck proof
            // is equal to last small poly sent by prover (`subclaim.expected_evaluation`). This
            // step can be done via PCS opening proofs for all steps but first (output of
            // inference) and last (input of inference)
            let computed_point = vp.evaluate(subclaim.point_flat().as_ref());

            // NOTE: this expected_evaluation is computed by the verifier on the "reduced"
            // last polynomial of the sumcheck protocol. It's easy to compute since it's a degree
            // one poly. However, it needs to be checked against the original polynomial and this
            // should/usually done via PCS.
            computed_point == subclaim.expected_evaluation
        });

        self.proof.push_step_proof(proof, claimed_sum);
    }

    pub fn prove<'a>(mut self, trace: InferenceTrace<'a, E>) -> Proof<E> {
        // TODO: input the commitments first to do proper FS

        // this is the random set of variables to fix at each step derived as the output of
        // sumcheck.
        // For the first step, so before the first sumcheck, we generate it from FS.
        // The dimension is simply the number of variables needed to address all the space of the
        // input vector.
        let mut randomness_to_fix = self
            .transcript
            .read_challenges(trace.final_output().len().ilog2() as usize);

        // we start by the output to prove up to the input, GKR style
        for (i, (input, step)) in trace.iter().rev().enumerate() {
            info!(
                "step {}: input.len = {:?}, step.matrix {:?}, step.output.len() = {:?}",
                i,
                input.len(),
                step.layer.dim(),
                step.output.len()
            );
            self.prove_step(randomness_to_fix, input, step);
            // this point is the last random point over which to evaluate the original polynomial.
            // In our case, the polynomial is actually 2 for dense layer: the matrix MLE and the
            // vector MLE.
            //
            // So normally the verifier should verify both of these poly at this point. However:
            // 1. For the matrix MLE, we rely on PCS opening proofs, which is another step of the
            //    prover flow.
            // 2. For the vector, we actually do a subsequent sumcheck to prove that the vector MLE
            //    is really equal to the claimed evaluation.
            randomness_to_fix = self.proof.steps.last().unwrap().proof.point.clone();
        }
        self.proof
    }
}

pub fn verify<E: ExtensionField>(
    ctx: Context<E>,
    proof: Proof<E>,
    io: IO<E>,
) -> anyhow::Result<()> {
    // TODO: make transcript absorb commitments first
    // 0. Derive the first randomness
    let mut transcript = default_transcript();
    let randomness_to_fix = transcript.read_challenges(io.output.len().ilog2() as usize);
    // 1. For the output, we manually evaluate the MLE and check if it's the same as what prover
    //    gave. Note prover could ellude that but it's simpler to avoid that special check right
    //    now.
    let output_mle = vector_to_mle(io.output);
    let computed_sum = output_mle.evaluate(&randomness_to_fix);
    let claimed_sum = *proof
        .steps
        .first()
        .expect("at least one layer")
        .claimed_output;
    ensure!(computed_sum == claimed_sum, "proof invalid for output");

    // 2. Verify each proof sequentially
    for (i, (step, aux)) in proof.steps.iter().zip(ctx.polys_aux).enumerate() {
        println!("verify {}: aux {:?}", i, aux);
        let subclaim =
            IOPVerifierState::<E>::verify(claimed_sum, &step.proof, &aux, &mut transcript);

        let layer_index = ctx.len() - i;

        /// Matrix is evaluated both from the partial randomness to fix from previous step AND from
        /// the output of the sumcheck proof
        /// W(r_i+1, r_i)
        let pcs_eval_input = randomness_to_fix
            .iter()
            .chain(subclaim.point_flat())
            .collect_vec();
        /// pcs_eval means this evaluation should come from a PCS opening proof
        let pcs_eval = ctx.evaluate_layer(layer_index, pcs_eval_input);

        ///////
        let mut vp = VirtualPolynomial::<E>::new(max_var);
        vp.add_mle_list(vec![mat_mle.into(), input_mle.into()], E::ONE);
        println!("prove : aux {:?}", vp.aux_info);
        let subclaim = IOPVerifierState::<E>::verify(claimed_sum, &step, &vp.aux_info, &mut t);
        // now assert that the polynomial evaluated at the random point of the sumcheck proof
        // is equal to last small poly sent by prover (`subclaim.expected_evaluation`). This
        // step can be done via PCS opening proofs for all steps but first (output of
        // inference) and last (input of inference)
        let computed_point = vp.evaluate(
            subclaim
                .point
                .iter()
                .map(|c| c.elements)
                .collect_vec()
                .as_ref(),
        );

        // NOTE: this expected_evaluation is computed by the verifier on the "reduced"
        // last polynomial of the sumcheck protocol. It's easy to compute since it's a degree
        // one poly. However, it needs to be checked against the original polynomial and this
        // should/usually done via PCS.
        computed_point == subclaim.expected_evaluation
    }

    let input_mle = vector_to_mle(io.input);
    Ok(())
}

#[cfg(test)]
mod test {
    use goldilocks::GoldilocksExt2;

    use crate::model::Model;

    use super::{Context, IO, Prover, verify};

    type F = GoldilocksExt2;
    use tracing_subscriber;

    #[test]
    fn test_prover_steps() {
        tracing_subscriber::fmt::init();
        let (model, input) = Model::<F>::random(1);
        let trace = model.run(input.clone());
        let output = trace.final_output();
        let ctx = Context::generate(&model);
        let io = IO::new(input, output.to_vec());
        let mut prover = Prover::new();
        let proof = prover.prove(trace);
        verify(ctx, proof, io).expect("invalid proof");
    }
}
